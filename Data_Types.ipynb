{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Types in UnifyML\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/holl-/UnifyML/blob/main/docs/Data_Types.ipynb)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üåê **UnifyML**](https://github.com/holl-/UnifyML)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üìñ **Documentation**](https://holl-.github.io/UnifyML/)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üîó **API**](https://holl-.github.io/UnifyML/unifyml)\n",
    "&nbsp; ‚Ä¢ &nbsp; [**‚ñ∂ Videos**]()\n",
    "&nbsp; ‚Ä¢ &nbsp; [<img src=\"images/colab_logo_small.png\" height=4>](https://colab.research.google.com/github/holl-/UnifyML/blob/main/docs/Examples.ipynb) [**Examples**](https://holl-.github.io/UnifyML/Examples.html)\n",
    "\n",
    "*Need to differentiate but your input is an `int` tensor?\n",
    "Need an `int64` tensor but got `int32`?\n",
    "Need a `tensor` but got an `ndarray`?\n",
    "Want an `ndarray` but your tensor is bound in a computational graph on the GPU?\n",
    "Worry no longer for UnifyML has you covered!*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !pip install --quiet unifyml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Floaing Point Precision\n",
    "\n",
    "A major difference between UnifyML and its backends is the handling of floating point (FP) precision.\n",
    "NumPy automatically casts arrays to the highest precision and other ML libraries will raise errors if data types do not match.\n",
    "Instead, UnifyML lets you set the FP precision globally using [`set_global_precision(64)`](unifyml/math/#unifyml.math.set_global_precision)\n",
    "or by context and automatically casts tensors to that precision when needed.\n",
    "The default is FP32 (single precision).\n",
    "Let's set the global precision to FP64 (double precision)!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from unifyml import math\n",
    "\n",
    "math.set_global_precision(64)  # double precision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From now on, all created float tensors will be of type `float64`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "float64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.zeros().dtype"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can run parts of our code with a different precision by executing them within a [`precision`](unifyml/math/#unifyml.math.precision) block:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "with math.precision(32):\n",
    "    print(math.zeros().dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "UnifyML automatically casts tensors to the current precision level during operations.\n",
    "Say we have a `float64` tensor but want to run 32-bit operations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "tensor64 = math.ones()\n",
    "with math.precision(32):\n",
    "    print(math.sin(tensor64).dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, the tensor was cast to `float32` before applying the `sin` function.\n",
    "If you want to explicitly cast a tensor to the current precision, use [`math.to_float()`](unifyml/math#unifyml.math.to_float)\n",
    "\n",
    "This system precludes any precision conflicts and you will never accidentally execute code with the wrong precision!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Specifying Data Types\n",
    "\n",
    "UnifyML provides a unified data type class, [`DType`](unifyml/math#unifyml.math.DType).\n",
    "However, you only need to specify the data type when creating a new `Tensor` from scratch.\n",
    "When wrapping an existing tensor, the data type is kept as-is."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[93mfloat16\u001B[0m \u001B[94m0.0\u001B[0m"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unifyml.math import DType\n",
    "\n",
    "math.zeros(dtype=DType(float, 16))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that there are no global variables for data types. Simplify specify the kind and bit-length in the `DType` constructor.\n",
    "Actually, the explicit constructor call to `DType()` is not necessary. You can also pass the kind and bit-length as a `tuple`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[93mfloat16\u001B[0m \u001B[94m0.0\u001B[0m"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.zeros(dtype=(float, 16))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In most cases, you want the bit-length to match the current floating point precision.\n",
    "Then, just specify the kind of data type (`bool`, `int`, `float`, or `complex`)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94m0\u001B[0m"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.zeros(dtype=int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[93mcomplex128\u001B[0m \u001B[94m0j\u001B[0m"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.zeros(dtype=complex)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94mFalse\u001B[0m"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.zeros(dtype=bool)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Further Reading\n",
    "\n",
    "[üåê **UnifyML**](https://github.com/holl-/UnifyML)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üìñ **Documentation**](https://holl-.github.io/UnifyML/)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üîó **API**](https://holl-.github.io/UnifyML/unifyml)\n",
    "&nbsp; ‚Ä¢ &nbsp; [**‚ñ∂ Videos**]()\n",
    "&nbsp; ‚Ä¢ &nbsp; [<img src=\"images/colab_logo_small.png\" height=4>](https://colab.research.google.com/github/holl-/UnifyML/blob/main/docs/Examples.ipynb) [**Examples**](https://holl-.github.io/UnifyML/Examples.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}