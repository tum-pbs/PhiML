{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NumPy and Constants\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/holl-/UnifyML/blob/main/docs/NumPy_Constants.ipynb)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üåê **UnifyML**](https://github.com/holl-/UnifyML)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üìñ **Documentation**](https://holl-.github.io/UnifyML/)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üîó **API**](https://holl-.github.io/UnifyML/unifyml)\n",
    "&nbsp; ‚Ä¢ &nbsp; [**‚ñ∂ Videos**]()\n",
    "&nbsp; ‚Ä¢ &nbsp; [<img src=\"images/colab_logo_small.png\" height=4>](https://colab.research.google.com/github/holl-/UnifyML/blob/main/docs/Examples.ipynb) [**Examples**](https://holl-.github.io/UnifyML/Examples.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from unifyml import math"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When you create a new Tensor in UnifyML without specifying what backend to use, it will create a NumPy tensor.\n",
    "You can check the corresponding backend for a `Tensor` using `.default_backend`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.random_uniform().default_backend"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The same is true if you `wrap` a NumPy array, even after specifying the default backend."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.use('jax')\n",
    "\n",
    "import numpy\n",
    "math.wrap(numpy.asarray([0, 1, 2])).default_backend"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tensors backed by NumPy are not differentiable, only run on the CPU, and functions acting on NumPy tensors cannot be JIT-compiled.\n",
    "So why would you ever want to use NumPy?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constants\n",
    "\n",
    "Put simply, tensors backed by NumPy represent constants in your computational graph.\n",
    "If you JIT-compile a function and call it with PyTorch tensors, all recorded PyTorch calls will be executed each time.\n",
    "All NumPy calls, however, will only be executed during tracing and never again (unless the function needs to be re-traced).\n",
    "\n",
    "Here's an example:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with a = \u001B[92m(vector·∂ú=2)\u001B[0m \u001B[93mint64\u001B[0m \u001B[94mjax tracer\u001B[0m, b = \u001B[94m(1, 2)\u001B[0m \u001B[93mint64\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\u001B[94m(1.841, 1.243)\u001B[0m"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@math.jit_compile\n",
    "def fun(a):\n",
    "    b = math.wrap([1, 2])\n",
    "    print(f\"Tracing with a = {a}, b = {b}\")\n",
    "    return a + math.sin(b ** 2)\n",
    "\n",
    "fun(math.tensor([1, 2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since `fun` is JIT-compiled, the Python function will always be called with tracer objects for `a`.\n",
    "However, since `b` is a wrapped NumPy array, `b ** 2` can be computed during JIT-compile time using NumPy.\n",
    "Consequently, the computational graph generated by Jax or PyTorch or TensorFlow only contains one multiplication.\n",
    "\n",
    "As NumPy tensors are represented the same way in UnifyML as ML tensors, we can change its dependency on variables later without modifying the later code."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with a = \u001B[92m(vector·∂ú=2)\u001B[0m \u001B[93mint64\u001B[0m \u001B[94mjax tracer\u001B[0m, b = \u001B[92m(vector·∂ú=2)\u001B[0m \u001B[93mint64\u001B[0m \u001B[94mjax tracer\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\u001B[94m(1.841, 1.243)\u001B[0m"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@math.jit_compile\n",
    "def fun(a):\n",
    "    b = a\n",
    "    print(f\"Tracing with a = {a}, b = {b}\")\n",
    "    return a + math.sin(b ** 2)\n",
    "\n",
    "fun(math.tensor([1, 2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, `b` is a JIT-compiled tensor that is tracked in the computational graph.\n",
    "\n",
    "Importantly, this principle also applies to complex functions, such as simulations.\n",
    "Say you have a simulation `sim(x)`.\n",
    "Then for a fixed `label`, the loss `|sim(prediction)-sim(label)|` only needs to compute `sim(prediction)` while the result of `sim(label)` is pre-computed while tracing the function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tracing Linear Functions\n",
    "\n",
    "NumPy also plays an important role in tracing linear functions to obtain an [explicit sparse matrix](Matrices.html) representation.\n",
    "If the linear function does not depend on any ML tensors, it will be represented as a NumPy array or SciPy sparse matrix, even when the default backend is not NumPy.\n",
    "New tensors created inside the linear function will also default to NumPy, overriding the global default backend."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Backend: numpy\n",
      "\u001B[92mx=0\u001B[0m    \u001B[94m 2.  0.  0. \u001B[0m along \u001B[92m~x\u001B[0m\n",
      "\u001B[92mx=1\u001B[0m    \u001B[94m 0.  2.  0. \u001B[0m along \u001B[92m~x\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "<2x3 sparse matrix of type '<class 'numpy.float32'>'\n\twith 2 stored elements in COOrdinate format>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lin(x):\n",
    "    two = math.tensor(2)\n",
    "    return two * x.x[:-1]\n",
    "\n",
    "matrix = math.matrix_from_function(lin, math.zeros(math.spatial(x=3)))[0]\n",
    "math.print(matrix, f\"Backend: {matrix.default_backend}\")\n",
    "matrix.native()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This allows preconditioners to be [computed at JIT-compile time](Linear_Solves.html#Preconditioned-Linear-Solves).\n",
    "If the linear function depends on ML tensors, the matrix will be represented as a corresponding sparse tensor."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax\n",
      "            Backend: jax\n",
      "\u001B[92mx=0\u001B[0m    \u001B[94m 2.  0.  0. \u001B[0m along \u001B[92m~x\u001B[0m\n",
      "\u001B[92mx=1\u001B[0m    \u001B[94m 0.  2.  0. \u001B[0m along \u001B[92m~x\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "BCOO(float32[2, 3], nse=2)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lin(x, a):\n",
    "    return a * x.x[:-1]\n",
    "\n",
    "matrix = math.matrix_from_function(lin, math.zeros(math.spatial(x=3)), math.tensor(2))[0]\n",
    "math.print(matrix, f\"Backend: {matrix.default_backend}\")\n",
    "matrix.native()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Further Reading\n",
    "\n",
    "[üåê **UnifyML**](https://github.com/holl-/UnifyML)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üìñ **Documentation**](https://holl-.github.io/UnifyML/unifyml/)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üîó **API**](https://holl-.github.io/UnifyML/unifyml)\n",
    "&nbsp; ‚Ä¢ &nbsp; [**‚ñ∂ Videos**]()\n",
    "&nbsp; ‚Ä¢ &nbsp; [<img src=\"images/colab_logo_small.png\" height=4>](https://colab.research.google.com/github/holl-/UnifyML/blob/main/docs/Examples.ipynb) [**Examples**](https://holl-.github.io/UnifyML/Examples.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}